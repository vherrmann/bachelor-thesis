\section{Complexity of input partitions}
\label{ch:partitions}

% TODO: what kind of shapes a d.t. â€¦
In the following we will analyze what shape the graph of a \rdtlifsnn has.
Since the output of the following layers only depends on the spike trains of the first hidden layer, those layers are only able to merge different output regions of the first hidden layer. We will therefore only study the output landscape of the first hidden layer.

We can therefore simplify the notation in this section by writing \(W,b,V,Î²,Ï‘,u,s\) for \(W^{[1]},b^{[1]},V^{[1]},Î²^{[1]},Ï‘^{[1]},u^{[1]},s^{[1]}\) respectively. Since we are using direct encoding, we will write \(x\) for \(s^{[0]}âˆˆâ„^{n_0}\):
% We can assume \(n_0=n_1=n\), \(W=I_{n_1}\) and \(b=0_{n_1}\), since we can instead just precompose our SNN \(Î¦\) with \(xâ†¦Wx+b\). Since precomposition can only decrease the number of different values, we can instead just study \(Î¦\) by itself.
  \begin{align}
    i(t) & = Î±i(t-1)+Wx+Vs(t-1) \\
    p(t) & = Î²u(t-1)+i(t)+b \\
    s(t) & = H(p(t)-Ï‘1_n) \\
    u(t) & = p(t)-Ï‘s(t)
  \end{align}

By using the simplified notation, we obtain the following explicitely formulated definitions from~\autoref{lem:non-recursive-defs} for \(xâˆˆâ„^{n_0}\) and \(s:\{0,1\}^{n_1Ã—t'}\) for \(t'\) chosen such that the following equations are well-defined:
\begin{align}
    i(t;x;s_p) &= Î±^ti(0)+\sum_{k=1}^tÎ±^{t-k}\left(Wx+Vs_p(k-1)\right), \\\label{eq:1}
    u(t;x;s_p) &= Î²^tu(0)+\sum_{k=1}^tÎ²^{t-k}\left(i(k;x;s_p)+b-Ï‘s_p(k)\right), \\\label{eq:2}
    p(t;x;s_p) &= Î²^tu(0)+\sum_{k=1}^tÎ²^{t-k}\left(i(k;x;s_p)+b\right)-Ï‘\sum_{k=1}^{t-1}Î²^{t-k}s_p(k), \\
    s(t;x;s_p) &= H(p(t;x;s_p)-Ï‘1_{n_1})
\end{align}

\begin{remark}\label{rem:regions-non-recursive-defs}
  We will sometimes just write \(i(t;x)\) instead of \(i(t;x;s_p)\), with which we imply to use \(s\) (at \(x\)) for \(s_p\). The same holds for \(u,p,s\).

  It is furthermore quite obvious that \(i\) grows linear in \(x\), given fixed \(s_p\). The same holds therefore for \(u\) and \(p\). Further, the interdependence of the different components in \(i/u/p/s\) is gone using a constant \(s_p\). We can therefore split e.g. \(p\) into functions \(p_{i;s_p}\) such that \(p(t,x)=p_{1;s_p}(t;x_1)Ã—â€¦Ã—p_{n_1;s_p}(t;x_{n_1})\).
  The functions \(p_{i;s_p}\) are not only linear in \(x\), but also grow monotonically in \(x\) since \(Î±,Î²â‰¥0\).
  So we in particular have that \(p\) to is growing monotonically (regarding by-component ordering).
  Since \(H\) is a monotonically growing function, \(s\) is also growing monotonically.
\end{remark}
We will examine the graph by investigating the shape and location of the constant regions of a \rdtlifsnn:

\begin{definition}
  The set of constant regions of a \rdtlifsnn \(Î¦\) is defined as the partition
  \[ C_Î¦â‰”\{R(Î¦)^{-1}(\{y\})\mid yâˆˆ\operatorname{im}(R(Î¦))\} \]
  of \(â„^{n_0}\). The set of constant regions of the first layer of a \rdtlifsnn \(Î¦\) is defined as
  \[ C_{Î¦,1}â‰”\{\{xâˆˆâ„^{n_0}\midâˆ€_ts(t;x)=s'(t)\}\mid s'âˆˆ\{0,1\}^{n_1Ã—T}\} \]
\end{definition}

% TODO: remark about the connection between C_Î¦ and C_{Î¦,1}

\begin{proposition}\label{prop:const-regions-cuboids}
  The constant regions of the first layer of a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\) are half-open cuboids.
\end{proposition}

\begin{lemma}\label{lem:intersection-and-product}
  \(\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=\prod_{iâˆˆ[n]}\bigcap_{jâˆˆJ}M_{i,j}\) for an index set \(J\) and sets \((M_{i,j})_{iâˆˆ[n],jâˆˆJ}\).
\end{lemma}

\begin{proof}[\proofofref{lem:intersection-and-product}]
  For every \(x=(x_i)_{iâˆˆ[n]}âˆˆMâ‰”\prod_{iâˆˆ[n]}\bigcup_{jâˆˆJ}M_{i,j}\) holds:
  \begin{equation*}
   xâˆˆ\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}â‡”âˆ€_{jâˆˆJ}xâˆˆ\prod_{iâˆˆ[n]}M_{i,j} â‡”âˆ€_{jâˆˆJ}âˆ€_{iâˆˆ[n]}x_iâˆˆM_{i,j}
  \end{equation*}
  On the other hand, we have
  \begin{equation*}
    xâˆˆ\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j}â‡”âˆ€_{iâˆˆ[n]}x_i\bigcap_{jâˆˆI}M_{i,j}â‡”âˆ€_{iâˆˆ[n]}âˆ€_{jâˆˆJ}x_iâˆˆM_{i,j}
  \end{equation*}
  In total we get
  \[ \bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=Mâˆ©\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=Mâˆ©\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j}=\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j} \]
\end{proof}

\begin{lemma}\label{lem:intersection-cuboid}
  The intersection \(C_1âˆ©C_2\) of half-open cuboids \(C_1,C_2âŠ‚â„^n\) is a half-open cuboid.
\end{lemma}

\begin{proof}[\proofofref{lem:intersection-cuboid}]
  %TODO: explicitely show case n=1?
  By definition of a half-open cuboid, we have half-open intervals \([c_{i,j},d_{i,j})\) with \(jâˆˆ[n]\) such that \(C_iâ‰”\prod_{jâˆˆ[n]}[c_{i,j},d_{i,j})\) for \(iâˆˆ[2]\). We therefore have
  \[ C_1âˆ©C_2=\prod_{jâˆˆ[n]}([c_{1,j},d_{1,j})âˆ©[c_{2,j},d_{2,j}))=\prod_{jâˆˆ[n]}([\max(c_{1,j},c_{2,j}),\min(d_{1,j},d_{2,j}))) \]
  by~\autoref{lem:intersection-and-product}
\end{proof}
%TODO: remark, we do allow empty cuboids?

%TODO: define cuboid/half-open?

\begin{lemma}\label{lem:pre-image-half-open-int}
  Let \([c,d)\) be a half-open interval and \(Ï†:â„â†’â„\) be an affine linear function. Then \(Ï†^{-1}([c,d))\) is a half-open interval.
\end{lemma}

%TODO: properly define half-open cuboid

\begin{proof}
  If \(Ï†\) is constant, then \(Ï†^{-1}([c,d))\) is either \(â„=[-âˆ,âˆ)\) or \(âˆ…=[0,0)\).
  If \(Ï†\) is not constant, then \(Ï†=ax+b\) with \(a>0\) and \(Ï†^{-1}([c,d))=[\frac{c-b}{a},\frac{d-b}{a})\), if \(c,dâˆˆâ„\); if \(c=-âˆ\) or \(d=âˆ\) the lower limit or upper limit of \(Ï†^{-1}([c,d))\) is \(-âˆ\) or \(âˆ\) respectively.
\end{proof}

\begin{proof}[\proofofref{prop:const-regions-cuboids}]
  Let \(CâˆˆC_{Î¦,1}\) be such a region and \(s_C\) the corresponding spike train. We then get
  \begin{align*}
    C&=\bigcap_{iâˆˆ[n_1],tâˆˆ[T]}\{x\mid (s_C)_i(t) =s_i(t;x)\} \\
     &=\bigcap_{iâˆˆ[n_1],tâˆˆ[T]}\{x\mid (s_C)_i(t) =s_i(t;x;s_C)\} \\
     &= \left(\bigcap_{\substack{iâˆˆ[n_1],tâˆˆ[T] \\ (s_C)_i(t)=0}}\{x\mid p_i(t;x;s_C)<Ï‘\}\right) \bigcap \left(\bigcap_{\substack{iâˆˆ[n_1],tâˆˆ[T] \\ (s_C)_i(t)=1}}\{x\mid p_i(t;x;s_C)â‰¥Ï‘\}\right)
  \end{align*}
  So \(C\) is an intersection of pre-images of half-open intervals regarding functions \(p_i(t;Â·;s_C)\). Since \(p_i(t;x;s_C)=p_{i;s_C}(t;Ï€_i(x);s_C)\) for all \(xâˆˆâ„^{n_0}\), and since \(p_{i;s_C}\) is linear and growing monotonically, we can apply~\autoref{lem:pre-image-half-open-int}. A pre-image of a half-open interval regarding \(p_i(t;Â·;s_C)\) is therefore a pre-image of a half-open interval regarding \(Ï€_i\), so a half-open cuboid.

  We can now apply~\autoref{lem:intersection-cuboid} and obtain that \(C\) is indeed a half-open cuboid.

  % . Let further \(x,yâˆˆC\). We now define the compact cuboid spanned by \(x,y\) as \(D_{x,y}â‰”[x,y]\).
  % % Here \([x_i,y_i]\) with \(x_i>y_i\) is to be understood as the interval \([y_i,x_i]\).
  % The first step of our proof is showing \(D_{x,y}âŠ‚C_{Î¦,1}\). W.l.o.g. we can assume that \(xâ‰¤y\) (in each component), otherwise we can replace \(x\) by \((\min(x_i,y_i))_i\) and \(y\) by \((\max(x_i,y_i))_i\). We therefore get \(zâˆˆD_{x,y}â‡”xâ‰¤zâ‰¤y\).

  % % TODO: widerspruchsbeweis unnÃ¶tig? Geht auch per Induktion
  % Suppose now a \(zâˆˆD_{x,y}âˆ–C_{Î¦,1}\) exists. We therefore have a \(t\) such that \(s(t;x)=s(t;y)â‰ s(t;z)\). Let \(t_0\) be the smallest such \(t\). We therefore have \(âˆ€_{t<t_0}s(t;x)=s(t;y)=s(t;z)\) and therefore get \(i(t;x)â‰¤i(t;z)â‰¤i(t;y)\) by~\eqref{eq:1} due to \(W=I_{n_1}\). From \(i(t;x)â‰¤i(t;z)â‰¤i(t;y)\) we can easily deduce \(p(t;x)â‰¤p(t;z)â‰¤p(t;y)\) and from that yet again we can conclude \(s(t;x)â‰¤s(t;z)â‰¤s(t;y)\), since \(H=Ï‡_{[1,âˆ]}\) rises monotonically.

  % Let us further consider

  % % We define \(q_Câ‰”(\inf_{xâˆˆC}x_i)_i\), \(p_Câ‰”(\sup_{xâˆˆC}x_i)_i\)
\end{proof}

We will add an ordering to spike trains based on lexicographical ordering. We define \(s'â‰¤_ls''\) for \(s',s''âˆˆ\{0,1\}^{n_1Ã—T}\) to mean that either \(s'=s''\) or \(s'(t)<s''(t)\) holds for the minimal time \(t\) such that the spike trains have different values.

\begin{lemma}
  Let us regard a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\).
  Let further \(x,yâˆˆâ„^{n_0}\). We then have \(xâ‰¤yâ‡’s(Â·;x)â‰¤s(Â·;y)\).
\end{lemma}

% TODO: introduce a<b means aâ‰¤b and âˆƒ_i(a_i<b_i)
\begin{proof}
  Let \(xâ‰¤y\) and \(s(Â·;x)â‰ s(Â·;y)\). We then have a minimal \(tâˆˆ[T]\) such \(s(t;x)â‰ s(t;y)\). Now due to \(âˆ€_{t'<t}s(t';x)=s(t';y)\) and~\autoref{rem:regions-non-recursive-defs} we have \(s(t;x)â‰¤s(t;y)\) and therefore \(s(t;x)<s(t;y)\).
\end{proof}

\begin{lemma}
  All (finite) vertices of the constant regions of the first layer of a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\) are contained in the convex hull of the points
  %TODO: imprecise notation
  \[ Pâ‰”\{xâˆˆâ„^{n_1}\mid Ïƒâˆˆ\{0,T\}^{n_1},C_{Ïƒ,T}=[a,b),âˆ€_ix_iâˆˆ\{a_i,b_i\},âˆ€_i(x_i=a_iâ‡”Ïƒ_i=0)\} \]
  We further have \(\operatorname{conv}(P)âŠ‚[a,b]\) where
  %TODO: improve inequalities
  \begin{align*}
   a &â‰” \\
   b &â‰”\max(-Î²u(0)-Î±i(0),)+(-b)+Ï‘Â·ğŸ™_{n_1}
  \end{align*}
  % where \(a_0\) is the higher vertex of the region \(C_0â‰”\{xâˆˆâ„^{n_0}\mid âˆ€_{tâˆˆ[T]}s(t;x)=0\}\), \(C_0=[a_0,b_0)\), with constant \(0\) spike train and \(b_1\) is the lower vertex of the region \(C_1â‰”\{xâˆˆâ„^{n_0}\mid âˆ€_{tâˆˆ[T]}s(t;x)=1\}\), \(C_1=[a_1,b_1)\) with constant \(1\) spike train.
\end{lemma}

\begin{proof}
  \(P\) is well-defined, sinceâ€¦
\end{proof}

% TODO: lexiographic ordering even in general case (with specific def.) and

% TODO: the regions appear only between â€¦

% TODO: generalize for W arbitrary

% TODO: show that limit can be reached/refer to previous paper

% \begin{lemma}
%   For \(yâˆˆâ„^{n_0}\) the mapping \(f_y:â„â†’\{0,1\}^T\) defined by \(xâ†¦s_i\) with \(s^{[0]}(t)=y+xe_i\) is monotone regarding lexical ordering.
% \end{lemma}

% TODO: motivation for theorem
While in theory we would expect the number of constant regions to grow exponentially with time, it grows only quadratically.

\begin{theorem}
A \rdtlifsnn with \(W=I_{n_1}\), â€¦ has at a maximum \((\frac{T^2+T}{2}+1)^n\) different constant regions.
\end{theorem}

\begin{proof}
  Since the number of constant regions of a \rdtlifsnn are just unions of the constant regions of the corresponding first layer, it suffices to compute the maximum number of constant regions of that layer.

  Let us consider by how much the regions can increase going from \(t-1\) to \(tâˆˆ[T]\). We can categorize the regions at \(t-1\) by the number of spikes they have in each component. We shall write \(C_{Ïƒ,t-1}\) for the region with sums \((Ïƒ_1,â€¦,Ïƒ_{n_1})=Ïƒâˆˆ[t-1]_0^{n_1}\) at time-step \(t-1\). Let further \(C_{Î£,t-1}â‰”\{C_{Ïƒ,t-1}\mid Ïƒâˆˆ[t-1]_0^{n_1}\}\). By definition we have \(\abs{C_{Î£,t-1}}â‰¤t^{n_1}\)..

  We will now show in each region \(C_{Ïƒ,t-1}\) only
\end{proof}
% Bobachtungen:
% In den Regionen zwischen Kreuzen ist die Anzahl der gestapelten Regionen nie grÃ¶ÃŸer gleich T
% In den Regionen um die Kreuze Ã¤hnliches

% Ãœberlegungen
% Regionen mit gleicher spike train in einer komponente anschauen, mit linien vergleichen?

\begin{corollary}
  %TODO: versions for W arbitrary
\end{corollary}

\begin{proof}
\end{proof}

%TODO: Î²<1 is essential
