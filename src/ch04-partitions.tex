\section{Complexity of input partitions}
\label{ch:partitions}

% TODO: what kind of shapes a d.t. â€¦
In the following we will analyze what shape the graph of a \rdtlifsnn has.
Since the output of the following layers only depends on the spike trains of the first hidden layer, those layers are only able to merge different output regions of the first hidden layer. We will therefore only study the output landscape of the first hidden layer.

We can therefore simplify the notation in this section by writing \(W,b,V,Î²,Ï‘,u,s\) for \(W^{[1]},b^{[1]},V^{[1]},Î²^{[1]},Ï‘^{[1]},u^{[1]},s^{[1]}\) respectively. Since we are using direct encoding, we will write \(x\) for \(s^{[0]}âˆˆâ„^{n_0}\):
% We can assume \(n_0=n_1=n\), \(W=I_{n_1}\) and \(b=0_{n_1}\), since we can instead just precompose our SNN \(Î¦\) with \(xâ†¦Wx+b\). Since precomposition can only decrease the number of different values, we can instead just study \(Î¦\) by itself.
  \begin{align}
    i(t) & = Î±i(t-1)+Wx+Vs(t-1) \\
    p(t) & = Î²u(t-1)+i(t)+b \\
    s(t) & = H(p(t)-Ï‘1_n) \\
    u(t) & = p(t)-Ï‘s(t)
  \end{align}

By using the simplified notation, we obtain the following explicitely formulated definitions from~\autoref{lem:non-recursive-defs} for \(xâˆˆâ„^{n_0}\) and \(s:\{0,1\}^{n_1Ã—t'}\) for \(t'\) chosen such that the following equations are well-defined:
\begin{align}
    i(t;x;s_p) &= Î±^ti(0)+\sum_{k=1}^tÎ±^{t-k}\left(Wx+Vs_p(k-1)\right), \\\label{eq:1}
    u(t;x;s_p) &= Î²^tu(0)+\sum_{k=1}^tÎ²^{t-k}\left(i(k;x;s_p)+b-Ï‘s_p(k)\right), \\\label{eq:2}
    p(t;x;s_p) &= Î²^tu(0)+\sum_{k=1}^tÎ²^{t-k}\left(i(k;x;s_p)+b\right)-Ï‘\sum_{k=1}^{t-1}Î²^{t-k}s_p(k), \\
    s(t;x;s_p) &= H(p(t;x;s_p)-Ï‘1_{n_1})
\end{align}

\begin{remark}\label{rem:regions-non-recursive-defs}
  We will sometimes just write \(i(t;x)\) instead of \(i(t;x;s_p)\), with which we imply to use \(s\) (at \(x\)) for \(s_p\). The same holds for \(u,p,s\).

  It is furthermore quite obvious that \(i\) grows linear in \(x\), given fixed \(s_p\). The same holds therefore for \(u\) and \(p\). Further, the interdependence of the different components in \(i/u/p/s\) is gone using a constant \(s_p\). We can therefore split e.g. \(p\) into functions \(p_{i;s_p}\) such that \(p(t,x)=p_{1;s_p}(t;x_1)Ã—â€¦Ã—p_{n_1;s_p}(t;x_{n_1})\).

  The functions \(i_{i;s_p}\),\(u_{i;s_p}\),\(p_{i;s_p}\) are not only linear in \(x\), but also grow monotonically in \(x\) since \(Î±,Î²â‰¥0\). If \(tâ‰¥1\), then \(i_{i;s_p}\),\(u_{i;s_p}\),\(p_{i;s_p}\) grow even strictly monotonically in \(x\).

  So we in particular have that \(p\) to is growing monotonically (regarding by-component ordering) on fixed \(s_p\).
  Since \(H\) is a monotonically growing function, \(s\) is also growing monotonically with fixed \(s_p\).
\end{remark}
We will examine the graph by investigating the shape and location of the constant regions of a \rdtlifsnn:

\begin{definition}
  The set of constant regions of a \rdtlifsnn \(Î¦\) is defined as the partition
  \[ C_Î¦â‰”\{R(Î¦)^{-1}(\{y\})\mid yâˆˆ\operatorname{im}(R(Î¦))\} \]
  of \(â„^{n_0}\). A constant region with spike train \(s'âˆˆ\{0,1\}^{n_1Ã—T}\), of the first layer of a \rdtlifsnn \(Î¦\) is defined as
  \[ C_{s'}â‰”\{xâˆˆâ„^{n_0}\midâˆ€_{tâˆˆ[T]}s(t;x)=s'(t)\} \]
  We further notate the set of these regions by \( C_{Î¦,1}â‰”\{C_{s'}\mid s'âˆˆ\{0,1\}^{n_1Ã—T},C_{s'}â‰ âˆ…\} \).
\end{definition}

% TODO: remark about the connection between C_Î¦ and C_{Î¦,1}

\begin{proposition}\label{prop:const-regions-cuboids}
  The constant regions of the first layer of a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\) are half-open cuboids.
\end{proposition}

\begin{lemma}\label{lem:intersection-and-product}
  \(\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=\prod_{iâˆˆ[n]}\bigcap_{jâˆˆJ}M_{i,j}\) for an index set \(J\) and sets \((M_{i,j})_{iâˆˆ[n],jâˆˆJ}\).
\end{lemma}

\begin{proof}[\proofofref{lem:intersection-and-product}]
  For every \(x=(x_i)_{iâˆˆ[n]}âˆˆMâ‰”\prod_{iâˆˆ[n]}\bigcup_{jâˆˆJ}M_{i,j}\) holds:
  \begin{equation*}
   xâˆˆ\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}â‡”âˆ€_{jâˆˆJ}xâˆˆ\prod_{iâˆˆ[n]}M_{i,j} â‡”âˆ€_{jâˆˆJ}âˆ€_{iâˆˆ[n]}x_iâˆˆM_{i,j}
  \end{equation*}
  On the other hand, we have
  \begin{equation*}
    xâˆˆ\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j}â‡”âˆ€_{iâˆˆ[n]}x_i\bigcap_{jâˆˆI}M_{i,j}â‡”âˆ€_{iâˆˆ[n]}âˆ€_{jâˆˆJ}x_iâˆˆM_{i,j}
  \end{equation*}
  In total we get
  \[ \bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=Mâˆ©\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=Mâˆ©\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j}=\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j} \]
\end{proof}

\begin{lemma}\label{lem:intersection-cuboid}
  The intersection \(C_1âˆ©C_2\) of half-open cuboids \(C_1,C_2âŠ‚â„^n\) is a half-open cuboid.
\end{lemma}

\begin{proof}[\proofofref{lem:intersection-cuboid}]
  %TODO: explicitely show case n=1?
  By definition of a half-open cuboid, we have half-open intervals \([c_{i,j},d_{i,j})\) with \(jâˆˆ[n]\) such that \(C_iâ‰”\prod_{jâˆˆ[n]}[c_{i,j},d_{i,j})\) for \(iâˆˆ[2]\). We therefore have
  \[ C_1âˆ©C_2=\prod_{jâˆˆ[n]}([c_{1,j},d_{1,j})âˆ©[c_{2,j},d_{2,j}))=\prod_{jâˆˆ[n]}([\max(c_{1,j},c_{2,j}),\min(d_{1,j},d_{2,j}))) \]
  by~\autoref{lem:intersection-and-product}
\end{proof}
%TODO: remark, we do allow empty cuboids?

%TODO: define cuboid/half-open?

\begin{lemma}\label{lem:pre-image-half-open-int}
  Let \([c,d)\) be a half-open interval and \(Ï†:â„â†’â„\) be an affine linear function. Then \(Ï†^{-1}([c,d))\) is a half-open interval.
\end{lemma}

%TODO: properly define half-open cuboid

\begin{proof}
  If \(Ï†\) is constant, then \(Ï†^{-1}([c,d))\) is either \(â„=[-âˆ,âˆ)\) or \(âˆ…=[0,0)\).
  If \(Ï†\) is not constant, then \(Ï†=ax+b\) with \(a>0\) and \(Ï†^{-1}([c,d))=[\frac{c-b}{a},\frac{d-b}{a})\), if \(c,dâˆˆâ„\); if \(c=-âˆ\) or \(d=âˆ\) the lower limit or upper limit of \(Ï†^{-1}([c,d))\) is \(-âˆ\) or \(âˆ\) respectively.
\end{proof}

\begin{proof}[\proofofref{prop:const-regions-cuboids}]
  Let \(CâˆˆC_{Î¦,1}\) be such a region and \(s_C\) the corresponding spike train. We then get
  \begin{align*}
    C&=\bigcap_{iâˆˆ[n_1],tâˆˆ[T]}\{x\mid (s_C)_i(t) =s_i(t;x)\} \\
     &=\bigcap_{iâˆˆ[n_1],tâˆˆ[T]}\{x\mid (s_C)_i(t) =s_i(t;x;s_C)\} \\
     &= \left(\bigcap_{\substack{iâˆˆ[n_1],tâˆˆ[T] \\ (s_C)_i(t)=0}}\{x\mid p_i(t;x;s_C)<Ï‘\}\right) \bigcap \left(\bigcap_{\substack{iâˆˆ[n_1],tâˆˆ[T] \\ (s_C)_i(t)=1}}\{x\mid p_i(t;x;s_C)â‰¥Ï‘\}\right)
  \end{align*}
  So \(C\) is an intersection of pre-images of half-open intervals regarding functions \(p_i(t;Â·;s_C)\). Since \(p_i(t;x;s_C)=p_{i;s_C}(t;Ï€_i(x);s_C)\) for all \(xâˆˆâ„^{n_0}\), and since \(p_{i;s_C}\) is linear and growing monotonically, we can apply~\autoref{lem:pre-image-half-open-int}. A pre-image of a half-open interval regarding \(p_i(t;Â·;s_C)\) is therefore a pre-image of a half-open interval regarding \(Ï€_i\), so a half-open cuboid.

  We can now apply~\autoref{lem:intersection-cuboid} and obtain that \(C\) is indeed a half-open cuboid.

  % . Let further \(x,yâˆˆC\). We now define the compact cuboid spanned by \(x,y\) as \(D_{x,y}â‰”[x,y]\).
  % % Here \([x_i,y_i]\) with \(x_i>y_i\) is to be understood as the interval \([y_i,x_i]\).
  % The first step of our proof is showing \(D_{x,y}âŠ‚C_{Î¦,1}\). W.l.o.g. we can assume that \(xâ‰¤y\) (in each component), otherwise we can replace \(x\) by \((\min(x_i,y_i))_i\) and \(y\) by \((\max(x_i,y_i))_i\). We therefore get \(zâˆˆD_{x,y}â‡”xâ‰¤zâ‰¤y\).

  % % TODO: widerspruchsbeweis unnÃ¶tig? Geht auch per Induktion
  % Suppose now a \(zâˆˆD_{x,y}âˆ–C_{Î¦,1}\) exists. We therefore have a \(t\) such that \(s(t;x)=s(t;y)â‰ s(t;z)\). Let \(t_0\) be the smallest such \(t\). We therefore have \(âˆ€_{t<t_0}s(t;x)=s(t;y)=s(t;z)\) and therefore get \(i(t;x)â‰¤i(t;z)â‰¤i(t;y)\) by~\eqref{eq:1} due to \(W=I_{n_1}\). From \(i(t;x)â‰¤i(t;z)â‰¤i(t;y)\) we can easily deduce \(p(t;x)â‰¤p(t;z)â‰¤p(t;y)\) and from that yet again we can conclude \(s(t;x)â‰¤s(t;z)â‰¤s(t;y)\), since \(H=Ï‡_{[1,âˆ]}\) rises monotonically.

  % Let us further consider

  % % We define \(q_Câ‰”(\inf_{xâˆˆC}x_i)_i\), \(p_Câ‰”(\sup_{xâˆˆC}x_i)_i\)
\end{proof}

We will add an ordering to spike trains based on lexicographical ordering. We define \(s'â‰¤_ls''\) for \(s',s''âˆˆ\{0,1\}^{n_1Ã—T}\) to mean that either \(s'=s''\) or \(s'(t)<s''(t)\) holds for the minimal time \(t\) such that the spike trains have different values.

\begin{lemma}
  Let us regard a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\).
  Let further \(x,yâˆˆâ„^{n_0}\). We then have \(xâ‰¤yâ‡’s(Â·;x)â‰¤s(Â·;y)\).
\end{lemma}

% TODO: introduce a<b means aâ‰¤b and âˆƒ_i(a_i<b_i)
\begin{proof}
  Let \(xâ‰¤y\) and \(s(Â·;x)â‰ s(Â·;y)\). We then have a minimal \(tâˆˆ[T]\) such \(s(t;x)â‰ s(t;y)\). Now due to \(âˆ€_{t'<t}s(t';x)=s(t';y)\) and~\autoref{rem:regions-non-recursive-defs} we have \(s(t;x)â‰¤s(t;y)\) and therefore \(s(t;x)<s(t;y)\).
\end{proof}

\begin{lemma}
  Let \(s'âˆˆ\{0,1\}^{n_1Ã—T}\) such that \(âˆ€_{iâˆˆ[n_1]}âˆ€_{t,t'}s'_i(t)=s'_i(t')\). Let further \(C_{s'}=[x^{s'},y^{s'})\) be the corresponding region. Then \(C_{s'}â‰ âˆ…\) and \(x_i=-âˆ\) if \(âˆ€_ts'_i(t)=0\) and \(y_i=âˆ\) if \(âˆ€_ts'_i(t)=0\) for all \(iâˆˆ[n_1]\).
\end{lemma}

\begin{proof}
  By~\autoref{rem:regions-non-recursive-defs} \(p_{i;s_p}(t;x)\) is a non-constant linear function for \(tâ‰¥1\) and fixed \(s_p\). We have therefore \(âˆƒ_zs_{i;s_p}(t;(-âˆ,z_i))=0\) and \(âˆƒ_zs_{i;s_p}(t;[z_i,âˆ))=1\) for any fixed \(tâˆˆ[T]\) and \(s_p\). Since there are only finitely many time-steps \(tâˆˆ[T]\) and spike trains \(s_p\) and, we can choose \(z\) with \(z_i\) small or large enough such that \(s_{i;s_p}(t;(-âˆ,z_i))=0\) or \(s_{i;s_p}(t;[z_i,âˆ))=1\) respectively for any \(s_p\) and \(tâˆˆ[T]\).

  By choosing the component \(z_i\) correctly small or large enough we therefore get a \(zâˆˆC_{s'}\). We further get for any \(iâˆˆ[n_1]\) that if \(âˆ€_ts'_i(t)=0\), then by construction \(s_i(t;(-âˆ,z_i))=1\), so \(âˆ€_{Î´>0}z-Î´e_iâˆˆC_{s'}\) and therefore \(x_i=-âˆ\). If on the other hand \(âˆ€_ts'_i(t)=1\), then \(s_i(t;[z_i,âˆ))=0\), so \(âˆ€_{Î´â‰¥0}z+Î´e_iâˆˆC_{s'}\) and therefore \(y_i=âˆ\).
\end{proof}

\begin{lemma}
  If \(qâˆˆâ„^{n_1}\) is a (finite) vertice of a region \(C_{s'}=[x^{s'},y^{s'})âˆˆC_{Î¦,1}\), \(s'âˆˆ\{0,1\}^{n_1Ã—T}\), then \(âˆ€_{iâˆˆ[n_1]}âˆ€_{Î´>0}s_i(Â·;q)â‰ s_i(Â·;q-Î´(âˆ‚_q)_ie_i)\).
  Here \(âˆ‚_qâ‰”2H(x^{s'}+y^{s'}-2q)-1\) points is a vector pointing from \(q\) roughly in the direction of the opposite vertice of the cube \(C_{s'}\) (We allow \(x^{s'},y^{s'}\) to have \(-âˆ\) or \(âˆ\) as components here).
\end{lemma}

\begin{proof}
  Proof by contradiction: If the statement is wrong, than there exists an \(iâˆˆ[n_1]\), such that for every \(Î´>0\) with \(s_i(Â·;q)=s_i(Â·;q-Î´âˆ‚_q_ie_i)\).
  Since the other components of \(p(Â·;x)\) as well as \(s(Â·;x)\) are only affected by the value of \(x_i\) through \(s_i(Â·;x)\) we further get \(s(Â·;q)=s(Â·;q-Î´âˆ‚_q_ie_i)\). So \(q-Î´âˆ‚_q_ie_iâˆˆC_{s'}\).

  On the other hand \(x^{s'}_iâ‰¤q_i-Î´(âˆ‚_q)_i<y^{s'}_i\) cannot be true: Assume that it is. Since \(q\) is a (finite) vertice of \([x^{s'},y^{s'})\), we have \(q_iâˆˆ\{x^{s'}_i,y^{s'}_i\}\). Case distinction: Suppose \(q_i=x^{s'}_i\). Then \((âˆ‚_q)_i=1\) and \(x^{s'}_iâ‰¤q_i-Î´(âˆ‚_q)_i\) is wrong. Suppose on the other hand \(q_i=y^{s'}_i\). Then \((âˆ‚_q)_i=-1\) and \(q_i-Î´(âˆ‚_q)_i<y^{s'}_i\) is wrong.
\end{proof}

\begin{lemma}
  All (finite) vertices of the constant regions of the first layer of a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\) are contained in the convex hull of the points
  %TODO: imprecise notation
  \[ Pâ‰”\{zâˆˆâ„^{n_1}\mid Ïƒâˆˆ\{0,T\}^{n_1},C_{Ïƒ,T}=[x,y),âˆ€_iz_iâˆˆ\{x_i,y_i\},âˆ€_i(z_i=x_iâ‡”Ïƒ_i=0)\} \]
  We further have \(\operatorname{conv}(P)âŠ‚[a,b]\) where
  %TODO: improve inequalities
  \begin{align*}
   a &â‰” \\
   b &â‰”\max(-Î²u(0)-Î±i(0),)+(-b)+Ï‘Â·ğŸ™_{n_1}
  \end{align*}
  % where \(a_0\) is the higher vertex of the region \(C_0â‰”\{xâˆˆâ„^{n_0}\mid âˆ€_{tâˆˆ[T]}s(t;x)=0\}\), \(C_0=[a_0,b_0)\), with constant \(0\) spike train and \(b_1\) is the lower vertex of the region \(C_1â‰”\{xâˆˆâ„^{n_0}\mid âˆ€_{tâˆˆ[T]}s(t;x)=1\}\), \(C_1=[a_1,b_1)\) with constant \(1\) spike train.
\end{lemma}

\begin{proof}
  \(P\) is well-defined, sinceâ€¦

  Let \(s'âˆˆ\{0,1\}^{n_1Ã—T}\) with \(C_{s'}â‰ âˆ…\) and \(C_{s'}=[x^{s'},y^{s'})\). Let further \(qâˆˆâ„^{n_1}\) be a (finite) vertice of \(C_{s'}\), so \(âˆ€_{iâˆˆ[n_1]}q_iâˆˆ\{x^{s'}_i,y^{s'}_i\}\). Suppose we have
\end{proof}

% TODO: lexiographic ordering even in general case (with specific def.) and

% TODO: the regions appear only between â€¦

% TODO: generalize for W arbitrary

% TODO: show that limit can be reached/refer to previous paper

% \begin{lemma}
%   For \(yâˆˆâ„^{n_0}\) the mapping \(f_y:â„â†’\{0,1\}^T\) defined by \(xâ†¦s_i\) with \(s^{[0]}(t)=y+xe_i\) is monotone regarding lexical ordering.
% \end{lemma}

% TODO: motivation for theorem
While in theory we would expect the number of constant regions to grow exponentially with time, it grows only quadratically.

\begin{theorem}\label{thm:bound-regions}
A \rdtlifsnn with \(W=I_{n_1}\), â€¦ has at a maximum \((\frac{T^2+T}{2}+1)^n\) different constant regions.
\end{theorem}

\begin{proof}
  Since the number of constant regions of a \rdtlifsnn are just unions of the constant regions of the corresponding first layer, it suffices to compute the maximum number of constant regions of that layer.

  Let us consider by how much the regions can increase going from \(t-1\) to \(tâˆˆ[T]\). We can categorize the regions at \(t-1\) by the number of spikes they have in each component. We shall write \(C_{Ïƒ,t-1}\) for the region with sums \((Ïƒ_1,â€¦,Ïƒ_{n_1})=Ïƒâˆˆ[t-1]_0^{n_1}\) at time-step \(t-1\). Let further \(C_{Î£,t-1}â‰”\{C_{Ïƒ,t-1}\mid Ïƒâˆˆ[t-1]_0^{n_1}\}\). By definition we have \(\abs{C_{Î£,t-1}}â‰¤t^{n_1}\)..

  We will now show in each region \(C_{Ïƒ,t-1}\) only
\end{proof}
% Bobachtungen:
% In den Regionen zwischen Kreuzen ist die Anzahl der gestapelten Regionen nie grÃ¶ÃŸer gleich T
% In den Regionen um die Kreuze Ã¤hnliches

% Ãœberlegungen
% Regionen mit gleicher spike train in einer komponente anschauen, mit linien vergleichen?
% TODO: comparison with Î²=1.5

\begin{corollary}
  %TODO: versions for W arbitrary
\end{corollary}

\begin{proof}
\end{proof}

%TODO: Î²<1 is essential
