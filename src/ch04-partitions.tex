\section{Complexity of input partitions}
\label{ch:partitions}

% TODO: what kind of shapes a d.t. â€¦
In the following we will analyze what shape the graph of a \rdtlifsnn has.
Since the output of the following layers only depends on the spike trains of the first hidden layer, those layers are only able to merge different output regions of the first hidden layer. We will therefore only study the output landscape of the first hidden layer.

We can therefore simplify the notation in this section by writing \(W,b,V,Î²,Ï‘,u,s\) for \(W^{[1]},b^{[1]},V^{[1]},Î²^{[1]},Ï‘^{[1]},u^{[1]},s^{[1]}\) respectively. Since we are using direct encoding, we will write \(x\) for \(s^{[0]}âˆˆâ„^{n_0}\):
% We can assume \(n_0=n_1=n\), \(W=I_{n_1}\) and \(b=0_{n_1}\), since we can instead just precompose our SNN \(Î¦\) with \(xâ†¦Wx+b\). Since precomposition can only decrease the number of different values, we can instead just study \(Î¦\) by itself.
  \begin{align}
    i(t) & = Î±i(t-1)+Wx+Vs(t-1) \\
    p(t) & = Î²u(t-1)+i(t)+b \\
    s(t) & = H(p(t)-Ï‘1_n) \\
    u(t) & = p(t)-Ï‘s(t)
  \end{align}

By using the simplified notation, we obtain the following explicitely formulated definitions from~\autoref{lem:non-recursive-defs} for \(xâˆˆâ„^{n_0}\) and \(s:\{0,1\}^{n_1Ã—t'}\) for \(t'\) chosen such that the following equations are well-defined:
\begin{align}
    i(t;x;s_p) &= Î±^ti(0)+\sum_{k=1}^tÎ±^{t-k}\left(Wx+Vs_p(k-1)\right), \\\label{eq:1}
    u(t;x;s_p) &= Î²^tu(0)+\sum_{k=1}^tÎ²^{t-k}\left(i(k;x;s_p)+b-Ï‘s_p(k)\right), \\\label{eq:2}
    p(t;x;s_p) &= Î²^tu(0)+\sum_{k=1}^tÎ²^{t-k}\left(i(k;x;s_p)+b\right)-Ï‘\sum_{k=1}^{t-1}Î²^{t-k}s_p(k), \\
    s(t;x;s_p) &= H(p(t;x;s_p)-Ï‘1_{n_1})
\end{align}

\begin{remark}\label{rem:regions-non-recursive-defs}
  We will sometimes just write \(i(t;x)\) instead of \(i(t;x;s_p)\), with which we imply to use \(s\) (at \(x\)) for \(s_p\). The same holds for \(u,p,s\).

  It is furthermore quite obvious that \(i\) grows linear in \(x\), given fixed \(s_p\). The same holds therefore for \(u\) and \(p\). Further, the interdependence of the different components in \(i/u/p/s\) is gone using a constant \(s_p\). We can therefore split e.g. \(p\) into functions \(p_{i;s_p}\) such that \(p(t,x)=p_{1;s_p}(t;x_1)Ã—â€¦Ã—p_{n_1;s_p}(t;x_{n_1})\).

  The functions \(i_{i;s_p}\),\(u_{i;s_p}\),\(p_{i;s_p}\) are not only linear in \(x\), but also grow monotonically in \(x\) since \(Î±,Î²â‰¥0\). If \(tâ‰¥1\), then \(i_{i;s_p}\),\(u_{i;s_p}\),\(p_{i;s_p}\) grow even strictly monotonically in \(x\).

  So we in particular have that \(p\) to is growing monotonically (regarding by-component ordering) on fixed \(s_p\).
  Since \(H\) is a monotonically growing function, \(s\) is also growing monotonically with fixed \(s_p\).
\end{remark}
We will examine the graph by investigating the shape and location of the constant regions of a \rdtlifsnn:

\begin{definition}
  The set of constant regions of a \rdtlifsnn \(Î¦\) is defined as the partition
  \[ C_Î¦â‰”\{R(Î¦)^{-1}(\{y\})\mid yâˆˆ\operatorname{im}(R(Î¦))\} \]
  of \(â„^{n_0}\). A constant region with spike train \(s'âˆˆ\{0,1\}^{n_1Ã—T}\), of the first layer of a \rdtlifsnn \(Î¦\) is defined as
  \[ C_{s'}â‰”\{xâˆˆâ„^{n_0}\midâˆ€_{tâˆˆ[T]}s(t;x)=s'(t)\} \]
  We further notate the set of these regions by \( C_{Î¦,1}â‰”\{C_{s'}\mid s'âˆˆ\{0,1\}^{n_1Ã—T},C_{s'}â‰ âˆ…\} \).
\end{definition}

% TODO: remark about the connection between C_Î¦ and C_{Î¦,1}

\begin{proposition}\label{prop:const-regions-cuboids}
  The constant regions of the first layer of a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\) are half-open cuboids.
\end{proposition}

\begin{lemma}\label{lem:intersection-and-product}
  \(\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=\prod_{iâˆˆ[n]}\bigcap_{jâˆˆJ}M_{i,j}\) for an index set \(J\) and sets \((M_{i,j})_{iâˆˆ[n],jâˆˆJ}\).
\end{lemma}

\begin{proof}[\proofofref{lem:intersection-and-product}]
  For every \(x=(x_i)_{iâˆˆ[n]}âˆˆMâ‰”\prod_{iâˆˆ[n]}\bigcup_{jâˆˆJ}M_{i,j}\) holds:
  \begin{equation*}
   xâˆˆ\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}â‡”âˆ€_{jâˆˆJ}xâˆˆ\prod_{iâˆˆ[n]}M_{i,j} â‡”âˆ€_{jâˆˆJ}âˆ€_{iâˆˆ[n]}x_iâˆˆM_{i,j}
  \end{equation*}
  On the other hand, we have
  \begin{equation*}
    xâˆˆ\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j}â‡”âˆ€_{iâˆˆ[n]}x_i\bigcap_{jâˆˆI}M_{i,j}â‡”âˆ€_{iâˆˆ[n]}âˆ€_{jâˆˆJ}x_iâˆˆM_{i,j}
  \end{equation*}
  In total we get
  \[ \bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=Mâˆ©\bigcap_{jâˆˆJ}\prod_{iâˆˆ[n]}M_{i,j}=Mâˆ©\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j}=\prod_{iâˆˆ[n]}\bigcap_{jâˆˆI}M_{i,j} \]
\end{proof}

\begin{lemma}\label{lem:intersection-cuboid}
  The intersection \(C_1âˆ©C_2\) of half-open cuboids \(C_1,C_2âŠ‚â„^n\) is a half-open cuboid.
\end{lemma}

\begin{proof}[\proofofref{lem:intersection-cuboid}]
  %TODO: explicitely show case n=1?
  By definition of a half-open cuboid, we have half-open intervals \([c_{i,j},d_{i,j})\) with \(jâˆˆ[n]\) such that \(C_iâ‰”\prod_{jâˆˆ[n]}[c_{i,j},d_{i,j})\) for \(iâˆˆ[2]\). We therefore have
  \[ C_1âˆ©C_2=\prod_{jâˆˆ[n]}([c_{1,j},d_{1,j})âˆ©[c_{2,j},d_{2,j}))=\prod_{jâˆˆ[n]}([\max(c_{1,j},c_{2,j}),\min(d_{1,j},d_{2,j}))) \]
  by~\autoref{lem:intersection-and-product}
\end{proof}
%TODO: remark, we do allow empty cuboids?

%TODO: define cuboid/half-open?

\begin{lemma}\label{lem:pre-image-half-open-int}
  Let \([c,d)\) be a half-open interval and \(Ï†:â„â†’â„\) be an affine linear function. Then \(Ï†^{-1}([c,d))\) is a half-open interval.
\end{lemma}

%TODO: properly define half-open cuboid

\begin{proof}
  If \(Ï†\) is constant, then \(Ï†^{-1}([c,d))\) is either \(â„=[-âˆ,âˆ)\) or \(âˆ…=[0,0)\).
  If \(Ï†\) is not constant, then \(Ï†=ax+b\) with \(a>0\) and \(Ï†^{-1}([c,d))=[\frac{c-b}{a},\frac{d-b}{a})\), if \(c,dâˆˆâ„\); if \(c=-âˆ\) or \(d=âˆ\) the lower limit or upper limit of \(Ï†^{-1}([c,d))\) is \(-âˆ\) or \(âˆ\) respectively.
\end{proof}

\begin{proof}[\proofofref{prop:const-regions-cuboids}]
  Let \(CâˆˆC_{Î¦,1}\) be such a region and \(s_C\) the corresponding spike train. We then get
  \begin{align*}
    C&=\bigcap_{iâˆˆ[n_1],tâˆˆ[T]}\{x\mid (s_C)_i(t) =s_i(t;x)\} \\
     &=\bigcap_{iâˆˆ[n_1],tâˆˆ[T]}\{x\mid (s_C)_i(t) =s_i(t;x;s_C)\} \\
     &= \left(\bigcap_{\substack{iâˆˆ[n_1],tâˆˆ[T] \\ (s_C)_i(t)=0}}\{x\mid p_i(t;x;s_C)<Ï‘\}\right) \bigcap \left(\bigcap_{\substack{iâˆˆ[n_1],tâˆˆ[T] \\ (s_C)_i(t)=1}}\{x\mid p_i(t;x;s_C)â‰¥Ï‘\}\right)
  \end{align*}
  So \(C\) is an intersection of pre-images of half-open intervals regarding functions \(p_i(t;Â·;s_C)\). Since \(p_i(t;x;s_C)=p_{i;s_C}(t;Ï€_i(x);s_C)\) for all \(xâˆˆâ„^{n_0}\), and since \(p_{i;s_C}\) is linear and growing monotonically, we can apply~\autoref{lem:pre-image-half-open-int}. A pre-image of a half-open interval regarding \(p_i(t;Â·;s_C)\) is therefore a pre-image of a half-open interval regarding \(Ï€_i\), so a half-open cuboid.

  We can now apply~\autoref{lem:intersection-cuboid} and obtain that \(C\) is indeed a half-open cuboid.

  % . Let further \(x,yâˆˆC\). We now define the compact cuboid spanned by \(x,y\) as \(D_{x,y}â‰”[x,y]\).
  % % Here \([x_i,y_i]\) with \(x_i>y_i\) is to be understood as the interval \([y_i,x_i]\).
  % The first step of our proof is showing \(D_{x,y}âŠ‚C_{Î¦,1}\). W.l.o.g. we can assume that \(xâ‰¤y\) (in each component), otherwise we can replace \(x\) by \((\min(x_i,y_i))_i\) and \(y\) by \((\max(x_i,y_i))_i\). We therefore get \(zâˆˆD_{x,y}â‡”xâ‰¤zâ‰¤y\).

  % % TODO: widerspruchsbeweis unnÃ¶tig? Geht auch per Induktion
  % Suppose now a \(zâˆˆD_{x,y}âˆ–C_{Î¦,1}\) exists. We therefore have a \(t\) such that \(s(t;x)=s(t;y)â‰ s(t;z)\). Let \(t_0\) be the smallest such \(t\). We therefore have \(âˆ€_{t<t_0}s(t;x)=s(t;y)=s(t;z)\) and therefore get \(i(t;x)â‰¤i(t;z)â‰¤i(t;y)\) by~\eqref{eq:1} due to \(W=I_{n_1}\). From \(i(t;x)â‰¤i(t;z)â‰¤i(t;y)\) we can easily deduce \(p(t;x)â‰¤p(t;z)â‰¤p(t;y)\) and from that yet again we can conclude \(s(t;x)â‰¤s(t;z)â‰¤s(t;y)\), since \(H=Ï‡_{[1,âˆ]}\) rises monotonically.

  % Let us further consider

  % % We define \(q_Câ‰”(\inf_{xâˆˆC}x_i)_i\), \(p_Câ‰”(\sup_{xâˆˆC}x_i)_i\)
\end{proof}

We will add an ordering to spike trains based on lexicographical ordering. We define \(s'â‰¤_ls''\) for \(s',s''âˆˆ\{0,1\}^{n_1Ã—T}\) to mean that either \(s'=s''\) or \(s'(t)<s''(t)\) holds for the minimal time \(t\) such that the spike trains have different values.

\begin{lemma}
  Let us regard a \rdtlifsnn \(Î¦\) with \(W=I_{n_1}\).
  Let further \(x,yâˆˆâ„^{n_0}\). We then have \(xâ‰¤yâ‡’s(Â·;x)â‰¤s(Â·;y)\).
\end{lemma}

% TODO: introduce a<b means aâ‰¤b and âˆƒ_i(a_i<b_i)
\begin{proof}
  Let \(xâ‰¤y\) and \(s(Â·;x)â‰ s(Â·;y)\). We then have a minimal \(tâˆˆ[T]\) such \(s(t;x)â‰ s(t;y)\). Now due to \(âˆ€_{t'<t}s(t';x)=s(t';y)\) and~\autoref{rem:regions-non-recursive-defs} we have \(s(t;x)â‰¤s(t;y)\) and therefore \(s(t;x)<s(t;y)\).
\end{proof}

\begin{lemma}\label{lem:inf-regions}
  Let \(s'âˆˆ\{0,1\}^{n_1Ã—T}\) such that \(âˆ€_{iâˆˆ[n_1]}âˆ€_{t,t'âˆˆ[T]}s'_i(t)=s'_i(t')\). Let further \(C_{s'}=[x^{s'},y^{s'})\) be the corresponding region. Then \(C_{s'}\) is non-empty, i.e. \(âˆ€_{iâˆˆ[n_1]}x^{s'}_i<y^{s'}_i\), and \(x^{s'}_i=-âˆ\) exactly if \(âˆ€_{tâˆˆ[T]}s'_i(t)=0\) and \(y^{s'}_i=âˆ\) exactly if \(âˆ€_{tâˆˆ[T]}s'_i(t)=1\) for all \(iâˆˆ[n_1]\).

  Furthermore, \(C_{s'}\) has exactly one finite vertex.
\end{lemma}

\begin{proof}
  By~\autoref{rem:regions-non-recursive-defs} \(p_{i;s_p}(t;x)\) is a non-constant linear function for \(tâ‰¥1\) and fixed \(s_p\). We have therefore \(âˆƒ_zs_{i;s_p}(t;(-âˆ,z_i))=0\) and \(âˆƒ_zs_{i;s_p}(t;[z_i,âˆ))=1\) for any fixed \(tâˆˆ[T]\) and \(s_p\). Since there are only finitely many time-steps \(tâˆˆ[T]\) and spike trains \(s_p\) and, we get \(s_{i;s_p}(t;(-âˆ,z_i))=0\) or \(s_{i;s_p}(t;[z_i,âˆ))=1\) respectively for any \(s_p\) and \(tâˆˆ[T]\), as well as any \(z\) with \(z_i\) small or large enough.

  By choosing the component \(z_i\) correctly small or large enough we therefore get a \(zâˆˆC_{s'}\). We further get for any \(iâˆˆ[n_1]\) that if \(âˆ€_ts'_i(t)=0\), then by construction \(s_i(t;(-âˆ,z_i))=1\), so \(âˆ€_{Î´>0}z-Î´e_iâˆˆC_{s'}\) and therefore \(x_i=-âˆ\). If on the other hand \(âˆ€_ts'_i(t)=1\), then \(s_i(t;[z_i,âˆ))=0\), so \(âˆ€_{Î´â‰¥0}z+Î´e_iâˆˆC_{s'}\) and therefore \(y_i=âˆ\).

  Since \(Tâ‰¥1\) by definition, we have either \(x^{s'}_i=-âˆ\) or \(y^{s'}_i=âˆ\) by definition of \(s'\) for each \(iâˆˆ[n_1]\). By choosing the only finite one from \(\{x^{s'}_i,y^{s'}_i\}\) for each \(iâˆˆ[n_1]\) we get the only finite vertex of \(C_{s'}\).
\end{proof}

%TODO: compute rough position
\begin{lemma}\label{lem:region-vertex}
  If \(qâˆˆâ„^{n_1}\) is a (finite) vertex of a region \(C_{s'}=[x^{s'},y^{s'})âˆˆC_{Î¦,1}\), \(s'âˆˆ\{0,1\}^{n_1Ã—T}\), then \(âˆ€_{iâˆˆ[n_1]}âˆ€_{Î´>0}s_i(Â·;q)â‰ s_i(Â·;q-Î´(âˆ‚_q)_ie_i)\).
  Here \(âˆ‚_qâ‰”2H(x^{s'}+y^{s'}-2q)-1\) points is a vector pointing from \(q\) roughly in the direction of the opposite vertex of the cube \(C_{s'}\) (We allow \(x^{s'},y^{s'}\) to have \(-âˆ\) or \(âˆ\) as components here).
\end{lemma}

\begin{proof}
  Proof by contradiction: If the statement is wrong, than there exists an \(iâˆˆ[n_1]\), such that for every \(Î´>0\) with \(s_i(Â·;q)=s_i(Â·;q-Î´(âˆ‚_q)_ie_i)\).
  Since the other components of \(p(Â·;x)\) as well as \(s(Â·;x)\) are only affected by the value of \(x_i\) through \(s_i(Â·;x)\) we further get \(s(Â·;q)=s(Â·;q-Î´(âˆ‚_q)_ie_i)\). So \(q-Î´(âˆ‚_q)_ie_iâˆˆC_{s'}\).

  On the other hand \(x^{s'}_iâ‰¤q_i-Î´(âˆ‚_q)_i<y^{s'}_i\) cannot be true: Assume that it is. Since \(q\) is a (finite) vertex of \([x^{s'},y^{s'})\), we have \(q_iâˆˆ\{x^{s'}_i,y^{s'}_i\}\). Case distinction: Suppose \(q_i=x^{s'}_i\). Then \((âˆ‚_q)_i=1\) and \(x^{s'}_iâ‰¤q_i-Î´(âˆ‚_q)_i\) is wrong. Suppose on the other hand \(q_i=y^{s'}_i\). Then \((âˆ‚_q)_i=-1\) and \(q_i-Î´(âˆ‚_q)_i<y^{s'}_i\) is wrong.
\end{proof}

%TODO: not essential/not actually needed in proof? still leave it?
\begin{lemma}\label{lem:convex-closure}
  Let \(MâŠ‚â„^n\) be convex. Then the closure \(\overline{M}\) is convex as well.
\end{lemma}

\begin{proof}
  Let \(x,yâˆˆ\operatorname{M}\) and \(tâˆˆ[0,1]\). We will proof \(zâ‰”x+(y-x)tâˆˆ\operatorname{M}\). By definition of the closure have sequences \((x_n)_{nâˆˆâ„•},(y_n)_{nâˆˆâ„•}âŠ‚M\) with \(x_nâ†’x\), \(y_nâ†’y\) for \(nâ†’âˆ\). We get a corresponding sequence \(z_nâ‰”x_n+(y_n-x_n)t\) with \(z_nâ†’z\), since
  \begin{align*}
   \abs{z-z_n} &=\abs{(x-x_n)(1-t)+(y-y_n)t} \\
               &â‰¤(1-t)\abs{x-x_n}+t\abs{y-y_n} \\
               &â†’0
  \end{align*}
  for \(nâ†’âˆ\).
\end{proof}

%TODO: remove collission of notation for H
\begin{lemma}\label{lem:sep-conv-set-and-point-by-hypr}
  Let \(MâŠ‚â„^n\) and \(xâˆˆâ„^mâˆ–\overline{\operatorname{conv}(M)}\). Then there exists an affine hyperplane \(HâŠ‚â„^m\) with \(xâˆˆH\) and \(Hâˆ©\operatorname{conv}(M)=âˆ…\).
\end{lemma}

% TODO: image
\begin{proof}
  Let now \(Î´=\operatorname{dist}(x,\operatorname{conv}(M))â‰”\inf_{yâˆˆ\operatorname{conv}(M)}(\norm{x-y}_2)\). We clearly have \(Î´>0\), since otherwise \(xâˆˆ\operatorname{\operatorname{conv(M)}}\). Let \((y_n)_{nâˆˆâ„•}\) be a sequence with \(\norm{x,y_n}_2â†’Î´\) for \(nâ†’âˆ\). Since \(â„^n\) is complete we can assume w.l.o.g. that \((y_n)_n\) converges to \(yâˆˆâ„^n\). We now choose \(Hâ‰”x+\{zâˆˆâ„^n\mid âŸ¨z,x-yâŸ©=0\}\). This is indeed a hyperplane, since \(\norm{x-y}_2=Î´>0\) and therefore \(xâ‰ y\).

  Suppose there is a \(zâˆˆHâˆ©\operatorname{conv}(M)\). We then have \(y'â‰”y+(z-y)\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}\). By using \(\norm{Â·}_2^2=âŸ¨Â·,Â·âŸ©\) we get
  \[ \norm{x-y'}_2^2=\norm{x-y-(z-y)\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}}_2^2=\norm{x-y}_2^2-\norm{(z-y)\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}}_2^2 \]
  since \(x-y'âŠ¥y'-y\):
  \begin{align*}
    &âŸ¨x-y',(z-y)\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}âŸ© \\
    &=\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}âŸ¨x-y-(z-y)\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2},z-yâŸ© \\
    &=\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}âŸ¨x-y,z-yâŸ©-\frac{âŸ¨x-y,z-yâŸ©^2}{\norm{z-y}_2^4}âŸ¨z-y,z-yâŸ© \\
    &=0
  \end{align*}
  So \(\norm{x-y'}_2<\norm{x-y}_2=Î´\), since \(xâ‰ y\) and \(zâ‰ y\) (\(yâˆ‰H\)). We further have \(\operatorname{dist}(y',\operatorname{conv}(M))=0\):

  First notice that \(0â‰¤\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}<1\). Since \(zâˆˆH\), we have \(âŸ¨z-x,x-yâŸ©=0\) and therefore \(\norm{x-y}_2^2+\norm{z-x}^2_2=\norm{z-y}_2^2\), so we get
  \[ âŸ¨x-y,z-yâŸ©â‰¤\norm{z-y}\norm{x-y}<\norm{z-y}^2 \]
  by the Cauchy-Schwarz-Inequality and \(zâ‰ x\). Notice that we can proof \(\frac{âŸ¨z-x,z-yâŸ©}{\norm{z-y}_2^2}<1\) in the same way.
  Since we have \(\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}+\frac{âŸ¨z-x,z-yâŸ©}{\norm{z-y}_2^2}=1\) we get \(0â‰¤\frac{âŸ¨x-y,z-yâŸ©}{\norm{z-y}_2^2}\).

  %TODO: notation [y,z]
  So \(y'âˆˆ[y,z]âŠ‚\overline{\operatorname{conv}(M)}\) by~\autoref{lem:convex-closure}.

  So there are \(y''âˆˆ\operatorname{conv}(M)\) with \(\norm{y''-y'}_2<Î´-\norm{x-y'}_2\) and we get \(\norm{x-y''}<Î´\). This contradicts the definition of \(Î´\).
\end{proof}

\begin{lemma}\label{lem:pov-hyprplane}
  If \(HâŠ‚â„^n\) is an affine hyperplane, then there exists a dimension \(iâˆˆ[n]\) such that \(Ï€_{[n]âˆ–\{i\}}(H)=â„^{n-1}\).
\end{lemma}

%TODO: intuition there is pov such that the plane appears to cover everything

\begin{proof}
  Suppose this is not the case. Let \(xâˆˆH\). Then \(0â‰ \ker(Ï€_{[n]âˆ–\{i\}}|_{H-x})âŠ‚\ker(Ï€_{[n]âˆ–\{i\}}|_{â„^n})â‰…â„\), and therefore \(e_iâˆˆH-x\). But this contradicts \(H-x\) having dimension \(n-1\).
\end{proof}

%TODO: general assumption W=I_{n_1}
\begin{proposition}
  Let \(P\) be the set of all finite vertices of regions \(C_{s'}\), \(s'âˆˆ\{0,1\}^{n_1Ã—T}\), with \(âˆ€_{iâˆˆ[n_1]}âˆ€_{t,t'âˆˆ[T]}s'_i(t)=s'_i(t')\). Then all (finite) vertices of the constant regions \(C_{s'}âˆˆC_{Î¦,1}\) with \(W=I_{n_1}\) are contained in the convex hull of \(P\).

  We further have \(\operatorname{conv}(P)âŠ‚[a,b]\) where
  %TODO: improve inequalities
  \begin{align*}
   a &â‰” \\
   b &â‰”\max(-Î²u(0)-Î±i(0),)+(-b)+Ï‘Â·ğŸ™_{n_1}
  \end{align*}
  % where \(a_0\) is the higher vertex of the region \(C_0â‰”\{xâˆˆâ„^{n_0}\mid âˆ€_{tâˆˆ[T]}s(t;x)=0\}\), \(C_0=[a_0,b_0)\), with constant \(0\) spike train and \(b_1\) is the lower vertex of the region \(C_1â‰”\{xâˆˆâ„^{n_0}\mid âˆ€_{tâˆˆ[T]}s(t;x)=1\}\), \(C_1=[a_1,b_1)\) with constant \(1\) spike train.
\end{proposition}

%TODO: add image

%TODO: add name for spike trains/regions with constant spike trains, simplify proofs/propositions

\begin{proof}
  %TODO: put in proposition
  We will first proof that if \(xâˆˆâ„^{n_1}\) is a point with \(âˆƒ_{iâˆˆ[n_1]}âˆƒ_{t,t'âˆˆ[T]}s'_i(t)â‰ s'_i(t')\), then \(xâˆˆ\operatorname{conv}(P)\). Suppose \(xâˆ‰\operatorname{conv}(P)\). Then there is an affine hyperplane \(HâŠ‚â„^{n_1}âˆ–\operatorname{conv}(P)\) with \(xâˆˆH\) by~\autoref{lem:sep-conv-set-and-point-by-hypr}. We further have by~\autoref{lem:pov-hyprplane}, that there is a dimension \(i'âˆˆ[n]\) such that \(Ï€_{[n]âˆ–\{i'\}}(H)=â„^{n-1}\). So \(x+e_{i'}âˆ‰H\) and we have a vector \(yâˆˆH\) such that \(âˆ€_{iâˆˆ[n]âˆ–\{i'\}}y_iâ‰ 0\).

  Let us now regard the region \(C_{s_y}\), where we define \(s_y\) such that \(âˆ€_{iâˆˆ[n]âˆ–\{i\}}âˆ€_{tâˆˆ[T]}(s_y)_i(t)=1â‡”y_iâ‰¥0â‡”y_i>0\), and \(âˆ€_t(s_y)_{i'}(t)=1\) exactly when \(x+e_{i'}\) and \(\operatorname{conv}(P)âŠ‚â„âˆ–H\) are on different connected components of \(â„^nâˆ–H\), i.e. there does not exist a path \(c:[0,1]â†’â„âˆ–H\) with \(c(0)=x+e_{i'}\) and ending with \(c(1)âˆˆ\operatorname{conv}(P)\). Since convex sets are trivially path connected, if such a path exists for any point in \(\operatorname{conv}(P)\), it exists for every point of \(\operatorname{conv}(P)\).

  By definition of \(s_y\) we can apply~\autoref{lem:inf-regions} and obtain that \(C_{s_y}\) has one finite vertex \(zâˆˆP\), that \(C_{s_y}=[x^{s_y},y^{s_y})\) with \(âˆ€_{iâˆˆ[n_1]}(x^{s_y})_i<(y^{s_y})_i\) and \(x^{s_y}_i=-âˆ\) if \(âˆ€_{tâˆˆ[T]}(s_y)_i(t)=0\) and \(y^{s_y}_i=âˆ\) if \(âˆ€_{tâˆˆ[T]}(s_y)_i(t)=1\) for all \(iâˆˆ[n_1]\). So by definition of \(s_y\) there exists a \(Î´>0\) such that \(âˆ€_{iâˆˆ[n]âˆ–i'}Î´y_iâˆˆ[x^{s_y}_i,y^{s_y}_i)\). The same holds for \(i=i'\): Suppose \((s_y)_{i'}(t)=1\). Then there does not exist a path between \(x+e_{i'}\) and \(z\) in \(â„^{n_1}âˆ–H\).

\end{proof}

% TODO: lexiographic ordering even in general case (with specific def.) and

% TODO: the regions appear only between â€¦

% TODO: generalize for W arbitrary

% TODO: show that limit can be reached/refer to previous paper

% \begin{lemma}
%   For \(yâˆˆâ„^{n_0}\) the mapping \(f_y:â„â†’\{0,1\}^T\) defined by \(xâ†¦s_i\) with \(s^{[0]}(t)=y+xe_i\) is monotone regarding lexical ordering.
% \end{lemma}

% TODO: motivation for theorem
While in theory we would expect the number of constant regions to grow exponentially with time, it grows only quadratically.

\begin{theorem}\label{thm:bound-regions}
A \rdtlifsnn with \(W=I_{n_1}\), â€¦ has at a maximum \((\frac{T^2+T}{2}+1)^n\) different constant regions.
\end{theorem}

\begin{proof}
  Since the number of constant regions of a \rdtlifsnn are just unions of the constant regions of the corresponding first layer, it suffices to compute the maximum number of constant regions of that layer.

  Let us consider by how much the regions can increase going from \(t-1\) to \(tâˆˆ[T]\). We can categorize the regions at \(t-1\) by the number of spikes they have in each component. We shall write \(C_{Ïƒ,t-1}\) for the region with sums \((Ïƒ_1,â€¦,Ïƒ_{n_1})=Ïƒâˆˆ[t-1]_0^{n_1}\) at time-step \(t-1\). Let further \(C_{Î£,t-1}â‰”\{C_{Ïƒ,t-1}\mid Ïƒâˆˆ[t-1]_0^{n_1}\}\). By definition we have \(\abs{C_{Î£,t-1}}â‰¤t^{n_1}\)..

  We will now show in each region \(C_{Ïƒ,t-1}\) only
\end{proof}
% Bobachtungen:
% In den Regionen zwischen Kreuzen ist die Anzahl der gestapelten Regionen nie grÃ¶ÃŸer gleich T
% In den Regionen um die Kreuze Ã¤hnliches

% Ãœberlegungen
% Regionen mit gleicher spike train in einer komponente anschauen, mit linien vergleichen?
% TODO: comparison with Î²=1.5

\begin{corollary}
  %TODO: versions for W arbitrary
\end{corollary}

\begin{proof}
\end{proof}

%TODO: Î²<1 is essential
